{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3 - Modeling and Evaluation\n",
    "\n",
    "You should have completed exercises 1 and 2 before this exercise. We use the same dataset \"train_FD001.txt\" as in the first two exercises. Additionally, a test set \"test_FD001.txt\" and the test set labels \"RUL_FD001.txt\" are available on moodle.\n",
    "\n",
    "The focus of this task lies on developing a machine learning model to estimate the remaining useful lifetime of aircraft engines. For the application of predictive maintenance, a very important task is to decide whether the aircraft engine is still in a healthy condition or if there are already signs of degradation and the remaining useful lifetime is already close to zero. To prevent failure and apply maintenance measures in time, you want to build a classifier that classifies the aircraft engines in healthy and faulty engines. For safety reasons, engines are defined as faulty, when their remaining useful lifetime is less than 30 cycles.\n",
    "\n",
    "To perform the classification task, a decision tree algorithm shall be used. Decision trees work by splitting the available data into subsets using a series of rule-based criteria. The topic of decision trees will also be covered more extensively in Lecture VIII."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datasets\n",
    "In Moodle, you can download the files “train_FD001.txt”, “test_FD001.txt” and “RUL_FD001.txt”. “Train_FD001” contains run-to-failure curves from several engines. The dataset contains in total 26 parameters that are shown in Table 1.\n",
    "For each data entry, the corresponding engine number and cycle number is given. All engines were simulated until failure, meaning that the cycle numbers reach from 1 to the end of life of the engines. Parameters 2 - 4 indicate the operating conditions that were input parameters for the simulation. The remaining parameters 5 - 25 are the simulated sensor data and therefore the output of the simulation.\n",
    "\n",
    "“Test_FD001” contains measurements of 100 engines. The parameters (operating conditions and sensor data) are the same as in the “train_FD001” file. However, the test set does not contain run-to-failure curves. The given cycles are only a section of the total operating time of the engines and do not end with a RUL of 0. Therefore, the “RUL_FD001” file provides the RUL at the last given cycle for each of the engines in the test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we load basic libraries."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Load the training data, rename columns if you wish to. Calculate the remaining useful lifetime (RUL) of the aircraft engines and append it to the dataframe. (Repetition from the first exercises)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Load and inspect the test data set. The test data set contains measurements of aircraft engines over a certain amount of cycles. However, these measurements are not run-to-failure curves and only an excerpt of the total lifetime of the engines."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Load the \"RUL_FD001.txt\" file. It contains the remaining useful lifetime of each engine in the test set at the end of the provided measurement period. Given this information, calculate the RUL for all provided data points in the test set and append your calculations to the test data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Create the label for the train and test data sets. An engine shall be classified as faulty (label = 1) if its RUL is below 30 and as healthy (label = 0) if it is above 30."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Construct the final data arrays for the machine learning model by extracting input features and output labels from the three datasets. As input features, you can use the available sensor data or a subset of it by excluding features with no variance (see Exercises 1 and 2). The output label is the label faulty/healthy that you have calculated in Question 4 of this exercise."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Split your training data into a training set and a validation set. Like that you have 3 datasets: a training, a validation and a test set. To do this, you can use the train_test_split function from scikit-learn library."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Train a decision tree classifier on the training data. Then, evaluate the performance of the classifier on the training and validation set. What can you conclude regarding possible overfitting or underfitting?\n",
    "\n",
    "Useful python functions for this are:\n",
    "- DecisionTreeClassifier from scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- Confusion_matrix and metrics like accuracy, precision, recall and f1-score from scikit-learn (https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. The decision tree has several hyperparameters that affect the complexity of the built tree. One of them is the \"max_depth\" parameter. It defines the maximum depth of the tree, that means the maximum number of nodes (decisions) until the final classification is made. Try different values for this parameter to learn the decision tree. Plot the f1-score of the learned classifiers for training and validation set over the \"max_depth\" parameter. Can you define an optimal value for this parameter?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Use the optimal hyperparameter value to learn the final classifier. Evaluate your model on the test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}